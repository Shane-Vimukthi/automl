{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "fork-of-project-dprep-series1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-22T14:27:14.302033Z",
          "iopub.execute_input": "2021-09-22T14:27:14.30317Z",
          "iopub.status.idle": "2021-09-22T14:27:17.268545Z",
          "shell.execute_reply.started": "2021-09-22T14:27:14.303126Z",
          "shell.execute_reply": "2021-09-22T14:27:17.267298Z"
        },
        "trusted": true,
        "id": "73j-HyJVHTab"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('always')\n",
        "warnings.filterwarnings('ignore')\n",
        "import time\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "%matplotlib inline\n",
        "plt.style.use('seaborn-whitegrid')\n",
        "\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import joblib\n",
        "\n",
        "from lightgbm import LGBMClassifier\n",
        "# from catboost import CatBoostClassifier\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\"\n",
        "\n",
        "pd.set_option('display.max_colwidth', -1)\n",
        "\n",
        "import warnings\n",
        "warnings.simplefilter('ignore')\n",
        "\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "# from catboost import Pool, cv, CatBoostClassifier, CatBoostRegressor"
      ],
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FUkTPy55IQh_",
        "outputId": "d849adc3-9e03-46f4-edf2-b526729ba461"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-23T00:24:48.031324Z",
          "iopub.execute_input": "2021-09-23T00:24:48.031625Z",
          "iopub.status.idle": "2021-09-23T00:24:48.604929Z",
          "shell.execute_reply.started": "2021-09-23T00:24:48.031596Z",
          "shell.execute_reply": "2021-09-23T00:24:48.604025Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 686
        },
        "id": "vHmKst9EHTad",
        "outputId": "470d23a0-abe0-4383-c406-31c264323439"
      },
      "source": [
        "av = pd.read_csv('/content/drive/MyDrive/final_project_msc/data/av_blackfriday/data_set_blackfriday_pred/train.csv')\n",
        "iris = pd.read_csv('/content/drive/MyDrive/final_project_msc/data/iris/IRIS.csv')\n",
        "titanic = pd.read_csv('/content/drive/MyDrive/final_project_msc/data/titanic/train.csv')\n",
        "print('train_set\\n')\n",
        "av.head()\n",
        "print('test_set \\n')\n",
        "iris.head()\n",
        "print('submission \\n')\n",
        "titanic.head()"
      ],
      "execution_count": 238,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_set\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>User_ID</th>\n",
              "      <th>Product_ID</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Age</th>\n",
              "      <th>Occupation</th>\n",
              "      <th>City_Category</th>\n",
              "      <th>Stay_In_Current_City_Years</th>\n",
              "      <th>Marital_Status</th>\n",
              "      <th>Product_Category_1</th>\n",
              "      <th>Product_Category_2</th>\n",
              "      <th>Product_Category_3</th>\n",
              "      <th>Purchase</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1000001</td>\n",
              "      <td>P00069042</td>\n",
              "      <td>F</td>\n",
              "      <td>0-17</td>\n",
              "      <td>10</td>\n",
              "      <td>A</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>8370</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1000001</td>\n",
              "      <td>P00248942</td>\n",
              "      <td>F</td>\n",
              "      <td>0-17</td>\n",
              "      <td>10</td>\n",
              "      <td>A</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>6.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>15200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1000001</td>\n",
              "      <td>P00087842</td>\n",
              "      <td>F</td>\n",
              "      <td>0-17</td>\n",
              "      <td>10</td>\n",
              "      <td>A</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1422</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1000001</td>\n",
              "      <td>P00085442</td>\n",
              "      <td>F</td>\n",
              "      <td>0-17</td>\n",
              "      <td>10</td>\n",
              "      <td>A</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>14.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1057</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1000002</td>\n",
              "      <td>P00285442</td>\n",
              "      <td>M</td>\n",
              "      <td>55+</td>\n",
              "      <td>16</td>\n",
              "      <td>C</td>\n",
              "      <td>4+</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>7969</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   User_ID Product_ID Gender  ... Product_Category_2  Product_Category_3 Purchase\n",
              "0  1000001  P00069042  F      ... NaN                NaN                  8370   \n",
              "1  1000001  P00248942  F      ...  6.0                14.0                15200  \n",
              "2  1000001  P00087842  F      ... NaN                NaN                  1422   \n",
              "3  1000001  P00085442  F      ...  14.0              NaN                  1057   \n",
              "4  1000002  P00285442  M      ... NaN                NaN                  7969   \n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 238
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test_set \n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal_length</th>\n",
              "      <th>sepal_width</th>\n",
              "      <th>petal_length</th>\n",
              "      <th>petal_width</th>\n",
              "      <th>species</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sepal_length  sepal_width  petal_length  petal_width      species\n",
              "0  5.1           3.5          1.4           0.2          Iris-setosa\n",
              "1  4.9           3.0          1.4           0.2          Iris-setosa\n",
              "2  4.7           3.2          1.3           0.2          Iris-setosa\n",
              "3  4.6           3.1          1.5           0.2          Iris-setosa\n",
              "4  5.0           3.6          1.4           0.2          Iris-setosa"
            ]
          },
          "metadata": {},
          "execution_count": 238
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "submission \n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Cabin</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Braund, Mr. Owen Harris</td>\n",
              "      <td>male</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>A/5 21171</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Cumings, Mrs. John Bradley (Florence Briggs Thayer)</td>\n",
              "      <td>female</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>PC 17599</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>C85</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>Heikkinen, Miss. Laina</td>\n",
              "      <td>female</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>STON/O2. 3101282</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
              "      <td>female</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113803</td>\n",
              "      <td>53.1000</td>\n",
              "      <td>C123</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Allen, Mr. William Henry</td>\n",
              "      <td>male</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>373450</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PassengerId  Survived  Pclass  ...     Fare Cabin  Embarked\n",
              "0  1            0         3       ...  7.2500   NaN   S       \n",
              "1  2            1         1       ...  71.2833  C85   C       \n",
              "2  3            1         3       ...  7.9250   NaN   S       \n",
              "3  4            1         1       ...  53.1000  C123  S       \n",
              "4  5            0         3       ...  8.0500   NaN   S       \n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 238
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-23T00:25:27.84853Z",
          "iopub.execute_input": "2021-09-23T00:25:27.848988Z",
          "iopub.status.idle": "2021-09-23T00:25:27.854918Z",
          "shell.execute_reply.started": "2021-09-23T00:25:27.848945Z",
          "shell.execute_reply": "2021-09-23T00:25:27.854103Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oNmfgTDOHTae",
        "outputId": "69c69ac1-d97a-410e-d2b0-bdd0707a7545"
      },
      "source": [
        "print(av.columns)\n",
        "print(iris.columns)\n",
        "print(titanic.columns)"
      ],
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['User_ID', 'Product_ID', 'Gender', 'Age', 'Occupation', 'City_Category',\n",
            "       'Stay_In_Current_City_Years', 'Marital_Status', 'Product_Category_1',\n",
            "       'Product_Category_2', 'Product_Category_3', 'Purchase'],\n",
            "      dtype='object')\n",
            "Index(['sepal_length', 'sepal_width', 'petal_length', 'petal_width',\n",
            "       'species'],\n",
            "      dtype='object')\n",
            "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
            "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-23T00:25:56.064505Z",
          "iopub.execute_input": "2021-09-23T00:25:56.064976Z",
          "iopub.status.idle": "2021-09-23T00:25:56.383905Z",
          "shell.execute_reply.started": "2021-09-23T00:25:56.064934Z",
          "shell.execute_reply": "2021-09-23T00:25:56.382882Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Y_osnndHTah",
        "outputId": "2373d98a-b6aa-4ea3-a61b-68b98ad402ff"
      },
      "source": [
        "av.info()\n",
        "print('av\\n')\n",
        "av.info()\n",
        "print('iris \\n')\n",
        "iris.info()\n",
        "print('titanic \\n')\n",
        "titanic.info()"
      ],
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 550068 entries, 0 to 550067\n",
            "Data columns (total 12 columns):\n",
            " #   Column                      Non-Null Count   Dtype  \n",
            "---  ------                      --------------   -----  \n",
            " 0   User_ID                     550068 non-null  int64  \n",
            " 1   Product_ID                  550068 non-null  object \n",
            " 2   Gender                      550068 non-null  object \n",
            " 3   Age                         550068 non-null  object \n",
            " 4   Occupation                  550068 non-null  int64  \n",
            " 5   City_Category               550068 non-null  object \n",
            " 6   Stay_In_Current_City_Years  550068 non-null  object \n",
            " 7   Marital_Status              550068 non-null  int64  \n",
            " 8   Product_Category_1          550068 non-null  int64  \n",
            " 9   Product_Category_2          376430 non-null  float64\n",
            " 10  Product_Category_3          166821 non-null  float64\n",
            " 11  Purchase                    550068 non-null  int64  \n",
            "dtypes: float64(2), int64(5), object(5)\n",
            "memory usage: 50.4+ MB\n",
            "av\n",
            "\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 550068 entries, 0 to 550067\n",
            "Data columns (total 12 columns):\n",
            " #   Column                      Non-Null Count   Dtype  \n",
            "---  ------                      --------------   -----  \n",
            " 0   User_ID                     550068 non-null  int64  \n",
            " 1   Product_ID                  550068 non-null  object \n",
            " 2   Gender                      550068 non-null  object \n",
            " 3   Age                         550068 non-null  object \n",
            " 4   Occupation                  550068 non-null  int64  \n",
            " 5   City_Category               550068 non-null  object \n",
            " 6   Stay_In_Current_City_Years  550068 non-null  object \n",
            " 7   Marital_Status              550068 non-null  int64  \n",
            " 8   Product_Category_1          550068 non-null  int64  \n",
            " 9   Product_Category_2          376430 non-null  float64\n",
            " 10  Product_Category_3          166821 non-null  float64\n",
            " 11  Purchase                    550068 non-null  int64  \n",
            "dtypes: float64(2), int64(5), object(5)\n",
            "memory usage: 50.4+ MB\n",
            "iris \n",
            "\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 150 entries, 0 to 149\n",
            "Data columns (total 5 columns):\n",
            " #   Column        Non-Null Count  Dtype  \n",
            "---  ------        --------------  -----  \n",
            " 0   sepal_length  150 non-null    float64\n",
            " 1   sepal_width   150 non-null    float64\n",
            " 2   petal_length  150 non-null    float64\n",
            " 3   petal_width   150 non-null    float64\n",
            " 4   species       150 non-null    object \n",
            "dtypes: float64(4), object(1)\n",
            "memory usage: 6.0+ KB\n",
            "titanic \n",
            "\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 891 entries, 0 to 890\n",
            "Data columns (total 12 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   PassengerId  891 non-null    int64  \n",
            " 1   Survived     891 non-null    int64  \n",
            " 2   Pclass       891 non-null    int64  \n",
            " 3   Name         891 non-null    object \n",
            " 4   Sex          891 non-null    object \n",
            " 5   Age          714 non-null    float64\n",
            " 6   SibSp        891 non-null    int64  \n",
            " 7   Parch        891 non-null    int64  \n",
            " 8   Ticket       891 non-null    object \n",
            " 9   Fare         891 non-null    float64\n",
            " 10  Cabin        204 non-null    object \n",
            " 11  Embarked     889 non-null    object \n",
            "dtypes: float64(2), int64(5), object(5)\n",
            "memory usage: 83.7+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZtLgSG-HTal"
      },
      "source": [
        "# First find the categorical/numerical and id, target columns\n",
        "* Remove the id columns or check on them and find wheather they can be changed \n",
        "* \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGQPUzuDe3aF"
      },
      "source": [
        "# for col in av.columns:\n",
        "#   print(col)"
      ],
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PtFRen8yagUG"
      },
      "source": [
        "id_cols = []\n",
        "target_cols = []\n",
        "cat_cols_obj = []\n",
        "num_cols_all = []\n",
        "# num_cols_cont = []\n",
        "# num_cols_cat = []\n",
        "num_cols_skewed = []\n",
        "num_cols_cor = []\n",
        "num_cols_norm = []\n",
        "num_cols_norm_outliers = []\n",
        "num_cols_skewed_outliers = []\n",
        "\n",
        "# these have only the good ones but null available features are also available\n",
        "num_cols_skewed_done = []\n",
        "num_cols_cor_done = []\n",
        "num_cols_norm_done = []\n",
        "num_cols_norm_outliers_done = []\n",
        "num_cols_skewed_outliers_done = []\n",
        "\n",
        "num_cols_skewed_null = []\n",
        "num_cols_cor_null = []\n",
        "num_cols_norm_null = []\n",
        "num_cols_norm_outliers_null = []\n",
        "num_cols_skewed_outliers_null = []\n",
        "cat_cols_obj_null = []\n",
        "num_cols_all_null = []\n",
        "cat_cols_obj_null_to_del = []\n",
        "num_cols_all_null_to_del = []\n",
        "\n",
        "# these set is the final set as the nulls are filtered and done\n",
        "num_cols_skewed_null_done = []\n",
        "num_cols_cor_null_done = []\n",
        "num_cols_norm_null_done = []\n",
        "num_cols_norm_outliers_null_done = []\n",
        "num_cols_skewed_outliers_null_done = []"
      ],
      "execution_count": 239,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WtigDwIkHTat"
      },
      "source": [
        "def feat_types(df, target):\n",
        "  start_time = time.clock()\n",
        "\n",
        "  id_cols = []\n",
        "  target_cols = []\n",
        "  cat_cols_obj = []\n",
        "  num_cols_all = []\n",
        "\n",
        "#     identify the target column and remove in this function\n",
        "  target_cols = [target]\n",
        "  df_original = df.copy()\n",
        "\n",
        "  \n",
        "  df.drop([target], axis=1, inplace=True) # remove the target column from the dataset\n",
        "  \n",
        "#     do identify the target column and convert to num if categorical\n",
        "  \n",
        "\n",
        "#     identify the ids and remove the ids\n",
        "  for col in df.columns:\n",
        "      # print(col)\n",
        "      perc_unique = df[col].nunique()/len(av[col])*100\n",
        "      if perc_unique > 97.0: # get the ids \n",
        "        id_cols.append(col)\n",
        "      elif df.dtypes[col] == 'object': # get the string cat features\n",
        "        cat_cols_obj.append(col)\n",
        "      else:\n",
        "        num_cols_all.append(col) # get all the other int and float numericals \n",
        "\n",
        "  ''' this cat variable identification is kept as a feature engineering method in the other modules\n",
        "      for col in num_cols_all():\n",
        "        if 10 > df_copy.col.nunique() > 2:\n",
        "          num_cols_cat.append(col)\n",
        "        else:\n",
        "          num_cols_cont.append(col)'''\n",
        "      \n",
        "# identify the cat cols in the numerical all columns in other words identify the discrete and continuous \n",
        "# num_cols_all = [i for i in df_copy.columns if i not in [target_col] and i not in id_cols and i not in cat_obj_cols]\n",
        "\n",
        "  print(time.clock() - start_time, \"seconds took to finish dtype identifier\") \n",
        "\n",
        "  return df, id_cols, target_cols, cat_cols_obj, num_cols_all\n",
        "  "
      ],
      "execution_count": 240,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wC0aUONVeCcu"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "07IhyVTaHTau",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1754475a-0696-45e2-a194-94029f480bcd"
      },
      "source": [
        "df_av, id_cols_av, target_cols_av, cat_cols_obj_av, num_cols_all_av =feat_types(av, 'Purchase')"
      ],
      "execution_count": 241,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.20939099999999655 seconds took to finish dtype identifier\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IcK5md4nHTau",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a3dc1de-a83f-460e-e839-e23ea824c7e4"
      },
      "source": [
        "# print('df_copy_av \\n',df_copy_av)\n",
        "print('id_cols_av \\n', id_cols_av)\n",
        "print('target_cols_av \\n', target_cols_av)\n",
        "print('cat_cols_obj_av \\n', cat_cols_obj_av)\n",
        "print('num_cols_all_av \\n', num_cols_all_av)"
      ],
      "execution_count": 242,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "id_cols_av \n",
            " []\n",
            "target_cols_av \n",
            " ['Purchase']\n",
            "cat_cols_obj_av \n",
            " ['Product_ID', 'Gender', 'Age', 'City_Category', 'Stay_In_Current_City_Years']\n",
            "num_cols_all_av \n",
            " ['User_ID', 'Occupation', 'Marital_Status', 'Product_Category_1', 'Product_Category_2', 'Product_Category_3']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GpiaWR_DHTau",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "outputId": "92b6ad0c-2cca-4e33-f283-c33870238c53"
      },
      "source": [
        "df_av.head()"
      ],
      "execution_count": 243,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>User_ID</th>\n",
              "      <th>Product_ID</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Age</th>\n",
              "      <th>Occupation</th>\n",
              "      <th>City_Category</th>\n",
              "      <th>Stay_In_Current_City_Years</th>\n",
              "      <th>Marital_Status</th>\n",
              "      <th>Product_Category_1</th>\n",
              "      <th>Product_Category_2</th>\n",
              "      <th>Product_Category_3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1000001</td>\n",
              "      <td>P00069042</td>\n",
              "      <td>F</td>\n",
              "      <td>0-17</td>\n",
              "      <td>10</td>\n",
              "      <td>A</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1000001</td>\n",
              "      <td>P00248942</td>\n",
              "      <td>F</td>\n",
              "      <td>0-17</td>\n",
              "      <td>10</td>\n",
              "      <td>A</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>6.0</td>\n",
              "      <td>14.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1000001</td>\n",
              "      <td>P00087842</td>\n",
              "      <td>F</td>\n",
              "      <td>0-17</td>\n",
              "      <td>10</td>\n",
              "      <td>A</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1000001</td>\n",
              "      <td>P00085442</td>\n",
              "      <td>F</td>\n",
              "      <td>0-17</td>\n",
              "      <td>10</td>\n",
              "      <td>A</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>14.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1000002</td>\n",
              "      <td>P00285442</td>\n",
              "      <td>M</td>\n",
              "      <td>55+</td>\n",
              "      <td>16</td>\n",
              "      <td>C</td>\n",
              "      <td>4+</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   User_ID Product_ID  ... Product_Category_2 Product_Category_3\n",
              "0  1000001  P00069042  ... NaN                NaN               \n",
              "1  1000001  P00248942  ...  6.0                14.0             \n",
              "2  1000001  P00087842  ... NaN                NaN               \n",
              "3  1000001  P00085442  ...  14.0              NaN               \n",
              "4  1000002  P00285442  ... NaN                NaN               \n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 243
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ozYQ64swK06g"
      },
      "source": [
        "# Highly corelated feature identification removal"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "id": "QFYs7EILb7C_",
        "outputId": "b0d2170d-5aa8-4a8c-b11e-8060215529cc"
      },
      "source": [
        "df_av.corr()"
      ],
      "execution_count": 244,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>User_ID</th>\n",
              "      <th>Occupation</th>\n",
              "      <th>Marital_Status</th>\n",
              "      <th>Product_Category_1</th>\n",
              "      <th>Product_Category_2</th>\n",
              "      <th>Product_Category_3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>User_ID</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.023971</td>\n",
              "      <td>0.020443</td>\n",
              "      <td>0.003825</td>\n",
              "      <td>0.001529</td>\n",
              "      <td>0.003419</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Occupation</th>\n",
              "      <td>-0.023971</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.024280</td>\n",
              "      <td>-0.007618</td>\n",
              "      <td>-0.000384</td>\n",
              "      <td>0.013263</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Marital_Status</th>\n",
              "      <td>0.020443</td>\n",
              "      <td>0.024280</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.019888</td>\n",
              "      <td>0.015138</td>\n",
              "      <td>0.019473</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Product_Category_1</th>\n",
              "      <td>0.003825</td>\n",
              "      <td>-0.007618</td>\n",
              "      <td>0.019888</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.540583</td>\n",
              "      <td>0.229678</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Product_Category_2</th>\n",
              "      <td>0.001529</td>\n",
              "      <td>-0.000384</td>\n",
              "      <td>0.015138</td>\n",
              "      <td>0.540583</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.543649</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Product_Category_3</th>\n",
              "      <td>0.003419</td>\n",
              "      <td>0.013263</td>\n",
              "      <td>0.019473</td>\n",
              "      <td>0.229678</td>\n",
              "      <td>0.543649</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     User_ID  ...  Product_Category_3\n",
              "User_ID             1.000000  ...  0.003419          \n",
              "Occupation         -0.023971  ...  0.013263          \n",
              "Marital_Status      0.020443  ...  0.019473          \n",
              "Product_Category_1  0.003825  ...  0.229678          \n",
              "Product_Category_2  0.001529  ...  0.543649          \n",
              "Product_Category_3  0.003419  ...  1.000000          \n",
              "\n",
              "[6 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 244
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wd57owX5HTau"
      },
      "source": [
        "# in here null values are not to be considered\n",
        "\n",
        "def cor_identifier(df, num_cols_all):\n",
        "  threshold = 0.9\n",
        "# get the corelations morethan 0.5\n",
        "  cormat= df.corr()\n",
        "  #get the most corelated features\n",
        "  feature =[]\n",
        "  value = []\n",
        "\n",
        "  for col in num_cols_all:\n",
        "    corrdata= cormat[col]\n",
        "    for i, index in enumerate(corrdata.index):\n",
        "        if abs(corrdata[index]) > threshold:\n",
        "            feature.append(index)\n",
        "            value.append(corrdata[index])\n",
        "    df_corr = pd.DataFrame(data= value, index= feature, columns=['corr_value'])\n",
        "      \n",
        "  return df_corr\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # def get_corr_features(corrdata, threshold):\n",
        "  #     feature = []\n",
        "  #     value = []\n",
        "  #     for i, index in enumerate(corrdata.index):\n",
        "  #         if abs(corrdata[index]) > threshold:\n",
        "  #             feature.append(index)\n",
        "  #             value.append(corrdata[index])\n",
        "  #     df = pd.DataFrame(data= value, index= feature, columns=['corr_value'])\n",
        "      \n",
        "  #     return df\n",
        "\n",
        "\n",
        "# corr_df = cor_identifier(av,num_cols_all_av)\n",
        "# corr_df"
      ],
      "execution_count": 245,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "id": "1oEGaa1aNv1V",
        "outputId": "70f57dc3-0ce7-4b1c-b09b-532cd5e4d83c"
      },
      "source": [
        "corr_df = cor_identifier(df_av, num_cols_all_av)\n",
        "corr_df"
      ],
      "execution_count": 246,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>corr_value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>User_ID</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Occupation</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Marital_Status</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Product_Category_1</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Product_Category_2</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Product_Category_3</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    corr_value\n",
              "User_ID             1.0       \n",
              "Occupation          1.0       \n",
              "Marital_Status      1.0       \n",
              "Product_Category_1  1.0       \n",
              "Product_Category_2  1.0       \n",
              "Product_Category_3  1.0       "
            ]
          },
          "metadata": {},
          "execution_count": 246
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C6cKSpBQOCFv"
      },
      "source": [
        "# Skewed continuous feature identification and treatment\n",
        "\n",
        "\n",
        "\n",
        "*   Important Notes:\n",
        "\n",
        "· If the skewness is between -0.5 and 0.5, the data are fairly symmetrical\n",
        "\n",
        "· If the skewness is between -1 and — 0.5 or between 0.5 and 1, the data are moderately skewed\n",
        "\n",
        "· If the skewness is less than -1 or greater than 1, the data are highly skewed\n",
        "Here is the syntax to show the skewness value\n",
        "\n",
        "pd.DataFrame(exam.skew(),columns=[‘skewness’])\n",
        "\n",
        "or\n",
        "\n",
        "dataFrame.skew(axis=1)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fe45GYFWLZXx"
      },
      "source": [
        "# skewed_num_cols = []\n",
        "# df_skew = av.skew(axis=0, skipna=True)\n",
        "# print(df_skew)\n",
        "# print(df_skew[1])\n",
        "# # df_skew = pd.DataFrame(data= value, index= feature, columns=['corr_value'])\n",
        "\n",
        "\n",
        "# #     feature = []\n",
        "# #     value = []\n",
        "# #     for i, index in enumerate(corrdata.index):\n",
        "# #         if abs(corrdata[index]) > threshold:\n",
        "# #             feature.append(index)\n",
        "# #             value.append(corrdata[index])\n",
        "# #     df = pd.DataFrame(data= value, index= feature, columns=['corr_value'])\n",
        "      "
      ],
      "execution_count": 224,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R1L19fXdT9tn"
      },
      "source": [
        "# cat_cols_obj_av = []\n",
        "# num_cols_all_av = []\n",
        "# id_cols_av = []\n",
        "# target_cols_av = []\n",
        "# id_cols = []\n",
        "# target_cols = []\n",
        "# cat_cols_obj = []\n",
        "# num_cols_all = []\n",
        "\n",
        "# av = pd.read_csv('/content/drive/MyDrive/final_project_msc/data/av_blackfriday/data_set_blackfriday_pred/train.csv')\n",
        "# df_av, id_cols_av, target_cols_av, cat_cols_obj_av, num_cols_all_av =feat_types(av, 'Purchase')"
      ],
      "execution_count": 177,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CdV2TDvMVMk5",
        "outputId": "097e3619-715e-4dc2-e68c-1fead1846046"
      },
      "source": [
        "print(cat_cols_obj_av)\n",
        "print(num_cols_all_av)"
      ],
      "execution_count": 247,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Product_ID', 'Gender', 'Age', 'City_Category', 'Stay_In_Current_City_Years']\n",
            "['User_ID', 'Occupation', 'Marital_Status', 'Product_Category_1', 'Product_Category_2', 'Product_Category_3']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "id": "6ymhvxNxUIRp",
        "outputId": "06c40c74-940f-44dc-c7a8-fd4893aa0c01"
      },
      "source": [
        "df_av.head()"
      ],
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>User_ID</th>\n",
              "      <th>Product_ID</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Age</th>\n",
              "      <th>Occupation</th>\n",
              "      <th>City_Category</th>\n",
              "      <th>Stay_In_Current_City_Years</th>\n",
              "      <th>Marital_Status</th>\n",
              "      <th>Product_Category_1</th>\n",
              "      <th>Product_Category_2</th>\n",
              "      <th>Product_Category_3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1000001</td>\n",
              "      <td>P00069042</td>\n",
              "      <td>F</td>\n",
              "      <td>0-17</td>\n",
              "      <td>10</td>\n",
              "      <td>A</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1000001</td>\n",
              "      <td>P00248942</td>\n",
              "      <td>F</td>\n",
              "      <td>0-17</td>\n",
              "      <td>10</td>\n",
              "      <td>A</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>6.0</td>\n",
              "      <td>14.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1000001</td>\n",
              "      <td>P00087842</td>\n",
              "      <td>F</td>\n",
              "      <td>0-17</td>\n",
              "      <td>10</td>\n",
              "      <td>A</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1000001</td>\n",
              "      <td>P00085442</td>\n",
              "      <td>F</td>\n",
              "      <td>0-17</td>\n",
              "      <td>10</td>\n",
              "      <td>A</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>14.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1000002</td>\n",
              "      <td>P00285442</td>\n",
              "      <td>M</td>\n",
              "      <td>55+</td>\n",
              "      <td>16</td>\n",
              "      <td>C</td>\n",
              "      <td>4+</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   User_ID Product_ID  ... Product_Category_2 Product_Category_3\n",
              "0  1000001  P00069042  ... NaN                NaN               \n",
              "1  1000001  P00248942  ...  6.0                14.0             \n",
              "2  1000001  P00087842  ... NaN                NaN               \n",
              "3  1000001  P00085442  ...  14.0              NaN               \n",
              "4  1000002  P00285442  ... NaN                NaN               \n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 172
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7QNLqfpOZQG"
      },
      "source": [
        "def skew_identifier(df):\n",
        "  start_time = time.clock()\n",
        "  num_cols_skewed = []\n",
        "  num_cols_norm = []\n",
        "  df_skew = df.skew(axis =0, skipna=True)\n",
        "  for col in df_skew.index:\n",
        "    if abs(df_skew[col]) >1:\n",
        "      num_cols_skewed.append(col)\n",
        "    else:\n",
        "      num_cols_norm.append(col)\n",
        "  print(time.clock() - start_time, \"seconds took to finish skew identifier\")\n",
        "  return num_cols_skewed, num_cols_norm"
      ],
      "execution_count": 248,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NHgL8cByoXrA"
      },
      "source": [
        "num_cols_skewed_av = []\n",
        "num_cols_norm_av = []\n",
        "# num_cols_skewed = []\n",
        "# num_cols_norm = []"
      ],
      "execution_count": 183,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OViq_XfPOx0T",
        "outputId": "08bc84c7-8b02-4666-c099-a0e5c84135cf"
      },
      "source": [
        "num_cols_skewed_av, num_cols_norm_av = skew_identifier(df_av)"
      ],
      "execution_count": 249,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.14598900000000015 seconds took to finish skew identifier\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E8JJTNcOwdYh"
      },
      "source": [
        "# av['Product_Category_3_log'] = np.log(av['Product_Category_3']+1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kC-dN9agwq0V"
      },
      "source": [
        "# av.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ujZBy6CLn-KG",
        "outputId": "d50936f9-dec2-4ee6-bcd7-77082f24147d"
      },
      "source": [
        "print(num_cols_skewed_av)\n",
        "print(num_cols_norm_av)"
      ],
      "execution_count": 250,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Product_Category_1']\n",
            "['User_ID', 'Occupation', 'Marital_Status', 'Product_Category_2', 'Product_Category_3']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VIrfR62PRwR5"
      },
      "source": [
        "'''def skewd_convo_test(df, num_cols_norm_av):\n",
        "  for col in num_cols_norm_av:\n",
        "    av = df_av.copy()\n",
        "    av[col+'_log'] = np.log(av[col]+1)\n",
        "\n",
        "  for col in num_cols_norm_av:\n",
        "    av = df_av.copy()\n",
        "    av[col+'_sqrt'] = av[col]**1/2\n",
        "  # av['Prod_cat_3_num_cols_skewed_log'] = np.log(av['Product_Category_3']+1)\n",
        "  return av'''"
      ],
      "execution_count": 159,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Y9kjpYWd-u8"
      },
      "source": [
        "from scipy.stats import boxcox\n",
        "\n",
        "def skew_fix(df, num_cols_skewed, num_cols_norm):\n",
        "  start_time = time.clock()\n",
        "  num_cols_skewed_done = []\n",
        "\n",
        "  # ln transformation\n",
        "  for col in num_cols_skewed:\n",
        "    new_col = str(col) + '_num_cols_skewed_log'\n",
        "    df[new_col] = np.log(df[col] + 1)\n",
        "    # add new colum to the new done list\n",
        "    num_cols_skewed_done.append(new_col)\n",
        "    print(df.head())\n",
        "  # squar root transformation \n",
        "  for col in num_cols_skewed:\n",
        "    new_col = str(col) + '_num_cols_skewed_sqr'\n",
        "    df[new_col] = df[col]**(1/2)\n",
        "    num_cols_skewed_done.append(new_col)\n",
        "    print(df.head())\n",
        "  \n",
        "  num_cols_norm = num_cols_norm + num_cols_skewed_done\n",
        "\n",
        "  # boxcox transformation\n",
        "  # for col in num_cols_skewed:\n",
        "  #   df[str(col)+'_num_cols_skewd'+'_boxcox'] = boxcox(df[col], lambda = None)\n",
        "  # df = pd.DataFrame()\n",
        "  print(time.clock() - start_time, \"seconds took to finish skew fix\")\n",
        "  return df, num_cols_skewed_done, num_cols_norm"
      ],
      "execution_count": 251,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DhSfDoa4lrap",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 588
        },
        "outputId": "0b45d68a-e3ea-4e16-af3e-eacadf0186da"
      },
      "source": [
        "df_av, num_cols_skewed_done_av, num_cols_norm_av = skew_fix(df_av,num_cols_skewed_av, num_cols_norm_av )\n",
        "df_av.head()"
      ],
      "execution_count": 252,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   User_ID  ... Product_Category_1_num_cols_skewed_log\n",
            "0  1000001  ...  1.386294                             \n",
            "1  1000001  ...  0.693147                             \n",
            "2  1000001  ...  2.564949                             \n",
            "3  1000001  ...  2.564949                             \n",
            "4  1000002  ...  2.197225                             \n",
            "\n",
            "[5 rows x 12 columns]\n",
            "   User_ID  ... Product_Category_1_num_cols_skewed_sqr\n",
            "0  1000001  ...  1.732051                             \n",
            "1  1000001  ...  1.000000                             \n",
            "2  1000001  ...  3.464102                             \n",
            "3  1000001  ...  3.464102                             \n",
            "4  1000002  ...  2.828427                             \n",
            "\n",
            "[5 rows x 13 columns]\n",
            "0.11021000000000925 seconds took to finish skew fix\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>User_ID</th>\n",
              "      <th>Product_ID</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Age</th>\n",
              "      <th>Occupation</th>\n",
              "      <th>City_Category</th>\n",
              "      <th>Stay_In_Current_City_Years</th>\n",
              "      <th>Marital_Status</th>\n",
              "      <th>Product_Category_1</th>\n",
              "      <th>Product_Category_2</th>\n",
              "      <th>Product_Category_3</th>\n",
              "      <th>Product_Category_1_num_cols_skewed_log</th>\n",
              "      <th>Product_Category_1_num_cols_skewed_sqr</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1000001</td>\n",
              "      <td>P00069042</td>\n",
              "      <td>F</td>\n",
              "      <td>0-17</td>\n",
              "      <td>10</td>\n",
              "      <td>A</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.386294</td>\n",
              "      <td>1.732051</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1000001</td>\n",
              "      <td>P00248942</td>\n",
              "      <td>F</td>\n",
              "      <td>0-17</td>\n",
              "      <td>10</td>\n",
              "      <td>A</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>6.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>0.693147</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1000001</td>\n",
              "      <td>P00087842</td>\n",
              "      <td>F</td>\n",
              "      <td>0-17</td>\n",
              "      <td>10</td>\n",
              "      <td>A</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.564949</td>\n",
              "      <td>3.464102</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1000001</td>\n",
              "      <td>P00085442</td>\n",
              "      <td>F</td>\n",
              "      <td>0-17</td>\n",
              "      <td>10</td>\n",
              "      <td>A</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>14.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.564949</td>\n",
              "      <td>3.464102</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1000002</td>\n",
              "      <td>P00285442</td>\n",
              "      <td>M</td>\n",
              "      <td>55+</td>\n",
              "      <td>16</td>\n",
              "      <td>C</td>\n",
              "      <td>4+</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.197225</td>\n",
              "      <td>2.828427</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   User_ID  ... Product_Category_1_num_cols_skewed_sqr\n",
              "0  1000001  ...  1.732051                             \n",
              "1  1000001  ...  1.000000                             \n",
              "2  1000001  ...  3.464102                             \n",
              "3  1000001  ...  3.464102                             \n",
              "4  1000002  ...  2.828427                             \n",
              "\n",
              "[5 rows x 13 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 252
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IrvZs5IfpvXw",
        "outputId": "a47540b0-629f-477d-ae45-6699d162c542"
      },
      "source": [
        "print(num_cols_norm_av)\n",
        "print(num_cols_skewed_done_av)\n"
      ],
      "execution_count": 253,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['User_ID', 'Occupation', 'Marital_Status', 'Product_Category_2', 'Product_Category_3', 'Product_Category_1_num_cols_skewed_log', 'Product_Category_1_num_cols_skewed_sqr']\n",
            "['Product_Category_1_num_cols_skewed_log', 'Product_Category_1_num_cols_skewed_sqr']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zdmzrk51SeBZ"
      },
      "source": [
        "# Identify the Outliers and keep or filter\n",
        "\n",
        "\n",
        "\n",
        "*   How to treat outliers?\n",
        "👉 Trimming: It excludes the outlier values from our analysis. By applying this technique our data becomes thin when there are more outliers present in the dataset. Its main advantage is its fastest nature.\n",
        "\n",
        "👉Capping: In this technique, we cap our outliers data and make the limit i.e, above a particular value or less than that value, all the values will be considered as outliers, and the number of outliers in the dataset gives that capping number.\n",
        "\n",
        "For Example, if you’re working on the income feature, you might find that people above a certain income level behave in the same way as those with a lower income. In this case, you can cap the income value at a level that keeps that intact and accordingly treat the outliers.\n",
        "\n",
        "👉Treat outliers as a missing value: By assuming outliers as the missing observations, treat them accordingly i.e, same as those of missing values.\n",
        "\n",
        "You can refer to the missing value article \n",
        "\n",
        "👉 Discretization: In this technique, by making the groups we include the outliers in a particular group and force them to behave in the same manner as those of other points in that group. This technique is also known as Binning.\n",
        "\n",
        "\n",
        "**Identifying the outliers**\n",
        "\n",
        "\n",
        "👉  The data points which fall below mean-3*(sigma) or above mean+3*(sigma) are outliers.\n",
        "\n",
        "\n",
        "👉 For Skewed distributions: Use Inter-Quartile Range (IQR) proximity rule.\n",
        "\n",
        "– The data points which fall below Q1 – 1.5 IQR or above Q3 + 1.5 IQR are outliers.\n",
        "\n",
        "where Q1 and Q3 are the 25th and 75th percentile of the dataset respectively, and IQR represents the inter-quartile range and given by Q3 – Q1.\n",
        "\n",
        "Interquartile Range (IQR) to Detect Outliers\n",
        "\n",
        "This article was published as a part of the Data Science Blogathon \n",
        "\n",
        "Introduction\n",
        "In my previous article, I talk about the theoretical concepts about outliers and trying to find the answer to the question: “When we have to drop outliers and when to keep outliers?”.\n",
        "\n",
        "To gain a better understanding of this article, firstly you have to read that  and then proceed with this so that you have a clear idea about the outlier analysis in Data Science Projects.\n",
        "\n",
        "In this article, we will try to give the answer to the following questions along with the Python implementation,\n",
        "\n",
        "👉 How to treat outliers?\n",
        "\n",
        "👉 How to detect outliers?\n",
        "\n",
        "👉 What are the techniques for outlier detection and removal?\n",
        "\n",
        " \n",
        "\n",
        "Let’s get started\n",
        "\n",
        "How to treat outliers?\n",
        "👉 Trimming: It excludes the outlier values from our analysis. By applying this technique our data becomes thin when there are more outliers present in the dataset. Its main advantage is its fastest nature.\n",
        "\n",
        "👉Capping: In this technique, we cap our outliers data and make the limit i.e, above a particular value or less than that value, all the values will be considered as outliers, and the number of outliers in the dataset gives that capping number.\n",
        "\n",
        "For Example, if you’re working on the income feature, you might find that people above a certain income level behave in the same way as those with a lower income. In this case, you can cap the income value at a level that keeps that intact and accordingly treat the outliers.\n",
        "\n",
        "👉Treat outliers as a missing value: By assuming outliers as the missing observations, treat them accordingly i.e, same as those of missing values.\n",
        "\n",
        "You can refer to the missing value article \n",
        "\n",
        "👉 Discretization: In this technique, by making the groups we include the outliers in a particular group and force them to behave in the same manner as those of other points in that group. This technique is also known as Binning.\n",
        "\n",
        "You can learn more about discretization .\n",
        "\n",
        "How to detect outliers?\n",
        "\n",
        "👉 For Normal distributions: Use empirical relations of Normal distribution.\n",
        "\n",
        "– The data points which fall below mean-3*(sigma) or above mean+3*(sigma) are outliers.\n",
        "\n",
        "where mean and sigma are the average value and standard deviation of a particular column.\n",
        "\n",
        "Characteristics of a Normal Distribution\n",
        "\n",
        "Fig. Characteristics of a Normal Distribution\n",
        "\n",
        "Image Source: \n",
        "\n",
        " \n",
        "\n",
        "👉 For Skewed distributions: Use Inter-Quartile Range (IQR) proximity rule.\n",
        "\n",
        "– The data points which fall below Q1 – 1.5 IQR or above Q3 + 1.5 IQR are outliers.\n",
        "\n",
        "where Q1 and Q3 are the 25th and 75th percentile of the dataset respectively, and IQR represents the inter-quartile range and given by Q3 – Q1.\n",
        "\n",
        "Interquartile Range (IQR) to Detect Outliers | Naysan Saran\n",
        "\n",
        "Fig. IQR to detect outliers\n",
        "\n",
        "Image Source: \n",
        "\n",
        " \n",
        "\n",
        "👉 For Other distributions: Use percentile-based approach.\n",
        "\n",
        "For Example, Data points that are far from 99% percentile and less than 1 percentile are considered an outlier.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "1v9VMJHhTOjn",
        "outputId": "c6489521-4732-435b-a911-b55b955fcf70"
      },
      "source": [
        "sns.boxplot(av['Product_Category_1'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fe22dce8350>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8c0QrIkuTuvR",
        "outputId": "cc5ac3ef-c823-4002-c2ea-defac6be4166"
      },
      "source": [
        "av.shape\n",
        "109694"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(550068, 12)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "109694"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nPI-G4dHTKRI",
        "outputId": "b390c018-09ea-4028-9e60-bb653a8c71ba"
      },
      "source": [
        "upper_limit_other =  av['Product_Category_1'].quantile(0.99)\n",
        "lower_limit_other =  av['Product_Category_1'].quantile(0.01)\n",
        "print(upper_limit_other)\n",
        "\n",
        "q1 = av['Product_Category_1'].quantile(0.25)\n",
        "q3 = av['Product_Category_1'].quantile(0.75)\n",
        "iqr = q3-q1\n",
        "upper_limit_skew = q1 + 1.5* iqr\n",
        "lower_limit_skew = q1 - 1.5*iqr \n",
        "outliers_skew = len(av[av['Product_Category_1']> upper_limit_skew])  + len(av[av['Product_Category_1'] < lower_limit_skew])\n",
        "print('skew', outliers_skew)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "18.0\n",
            "skew 34993\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hwixYy1BQjFl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c486a5a8-724e-4133-ecdc-752d1ca0c8c0"
      },
      "source": [
        "# normal distributions\n",
        "outliers_norm = av[av['Product_Category_1'] > av['Product_Category_1'].mean() + 3 * av['Product_Category_1'].std()]\n",
        "print(len(outliers_norm))\n",
        "\n",
        "# skewed distributions\n",
        "q1 = av['Purchase'].quantile(0.25)\n",
        "q3 = av['Purchase'].quantile(0.75)\n",
        "iqr = q3-q1\n",
        "upper_limit_skew = q1 + 1.5* iqr\n",
        "lower_limit_skew = q1 - 1.5*iqr \n",
        "outliers_skew = len(av[av['Purchase']> upper_limit_skew])  + len(av[av['Purchase'] < lower_limit_skew])\n",
        "print(outliers_skew)\n",
        "\n",
        "\n",
        "# other distributions\n",
        "\n",
        "upper_limit_other =  av['Purchase'].quantile(0.99)\n",
        "lower_limit_other =  av['Purchase'].quantile(0.01)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7278\n",
            "109694\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CX37FGfEep5B"
      },
      "source": [
        "# Outlier identification and fixing \n",
        "* seems like that can be possible as in this case only capping is done"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iqUGFVJ5Scni"
      },
      "source": [
        "def outlier_identifier_fix(df, num_cols_norm, num_cols_skewed):\n",
        "  start_time = time.clock()\n",
        "\n",
        "  num_cols_norm_outliers = []\n",
        "  num_cols_skewed_outliers = []\n",
        "  num_cols_norm_outliers_done = []\n",
        "  num_cols_skewed_outliers_done = []\n",
        "  # num_cols_skewed_done_outliers = [] skewed done means they are normal so add to the normal list\n",
        "  # num_cols_skewed_done_outliers_done = []\n",
        "  \n",
        "\n",
        "# outliers which follow the normal distribution\n",
        "  for col in num_cols_norm: \n",
        "    upper_limit_norm = df[col].mean() + 3*df[col].std()\n",
        "    lower_limit_norm = df[col].mean() - 3*df[col].std()\n",
        "    outliers_norm = df[df[col] > upper_limit_norm] + df[df[col] < lower_limit_norm]\n",
        "    if len(outliers_norm) >= 1:\n",
        "      num_cols_norm_outliers.append(col)\n",
        "      # fixing the outliers norm   ----------------------------------------------------------- capping\n",
        "      new_col = str(col)+'_num_cols_norm_outliers_cap'\n",
        "      df[new_col] = np.where(df[col]>upper_limit_norm, upper_limit_norm,np.where(df[col]<lower_limit_norm,lower_limit_norm,df[col]))\n",
        "      num_cols_norm_outliers_done.append(new_col)      \n",
        "\n",
        "\n",
        "# outliers which are skewed \n",
        "  for col in num_cols_skewed:\n",
        "    q1 = df[col].quantile(0.25)\n",
        "    q3 = df[col].quantile(0.75)\n",
        "    iqr = q3-q1\n",
        "    upper_limit_skew = q1 + 1.5* iqr\n",
        "    lower_limit_skew = q1 - 1.5* iqr \n",
        "    outliers_skew = len(df[df[col]> upper_limit_skew])  + len(df[df[col] < lower_limit_skew])\n",
        "    if outliers_skew >= 1:\n",
        "      num_cols_skewed_outliers.append(col)\n",
        "      # fixing the outliers skewed   -------------------------------------------------------------- capping\n",
        "      new_col = str(col)+'_num_cols_skewed_outliers_cap'\n",
        "      df[new_col] = np.where(df[col] > upper_limit_skew,upper_limit_skew,np.where(df[col] < lower_limit_skew,lower_limit_skew,df[col]))\n",
        "      num_cols_skewed_outliers_done.append(new_col)\n",
        "  \n",
        "\n",
        "  num_cols_norm = num_cols_norm + num_cols_norm_outliers_done + num_cols_skewed_outliers_done \n",
        "\n",
        "  print(time.clock() - start_time, \"seconds took to finish outlier identifier and fix\")\n",
        "\n",
        "  return df, num_cols_skewed_outliers, num_cols_norm_outliers, num_cols_norm_outliers_done, num_cols_skewed_outliers_done, num_cols_norm"
      ],
      "execution_count": 254,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h9KJ-ecHelKB",
        "outputId": "bf2d44b9-a9e1-4519-f3a5-44a2dab28a8f"
      },
      "source": [
        "df_av, num_cols_skewed_outliers_av, num_cols_norm_outliers_av, num_cols_norm_outliers_done_av, num_cols_skewed_done_av, num_cols_norm_av = outlier_identifier_fix(df_av, num_cols_norm_av, num_cols_skewed_av)"
      ],
      "execution_count": 255,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.14160099999999431 seconds took to finish outlier identifier and fix\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "xpGWUFWnlaXm",
        "outputId": "2e0dcf52-c918-4d97-e490-009fe3820fc6"
      },
      "source": [
        "df_av.head()"
      ],
      "execution_count": 256,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>User_ID</th>\n",
              "      <th>Product_ID</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Age</th>\n",
              "      <th>Occupation</th>\n",
              "      <th>City_Category</th>\n",
              "      <th>Stay_In_Current_City_Years</th>\n",
              "      <th>Marital_Status</th>\n",
              "      <th>Product_Category_1</th>\n",
              "      <th>Product_Category_2</th>\n",
              "      <th>Product_Category_3</th>\n",
              "      <th>Product_Category_1_num_cols_skewed_log</th>\n",
              "      <th>Product_Category_1_num_cols_skewed_sqr</th>\n",
              "      <th>Product_Category_1_num_cols_skewed_outliers_cap</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1000001</td>\n",
              "      <td>P00069042</td>\n",
              "      <td>F</td>\n",
              "      <td>0-17</td>\n",
              "      <td>10</td>\n",
              "      <td>A</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.386294</td>\n",
              "      <td>1.732051</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1000001</td>\n",
              "      <td>P00248942</td>\n",
              "      <td>F</td>\n",
              "      <td>0-17</td>\n",
              "      <td>10</td>\n",
              "      <td>A</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>6.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>0.693147</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1000001</td>\n",
              "      <td>P00087842</td>\n",
              "      <td>F</td>\n",
              "      <td>0-17</td>\n",
              "      <td>10</td>\n",
              "      <td>A</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.564949</td>\n",
              "      <td>3.464102</td>\n",
              "      <td>11.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1000001</td>\n",
              "      <td>P00085442</td>\n",
              "      <td>F</td>\n",
              "      <td>0-17</td>\n",
              "      <td>10</td>\n",
              "      <td>A</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>14.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.564949</td>\n",
              "      <td>3.464102</td>\n",
              "      <td>11.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1000002</td>\n",
              "      <td>P00285442</td>\n",
              "      <td>M</td>\n",
              "      <td>55+</td>\n",
              "      <td>16</td>\n",
              "      <td>C</td>\n",
              "      <td>4+</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.197225</td>\n",
              "      <td>2.828427</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   User_ID  ... Product_Category_1_num_cols_skewed_outliers_cap\n",
              "0  1000001  ...  3.0                                           \n",
              "1  1000001  ...  1.0                                           \n",
              "2  1000001  ...  11.5                                          \n",
              "3  1000001  ...  11.5                                          \n",
              "4  1000002  ...  8.0                                           \n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 256
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9i4mvkjgqb5w",
        "outputId": "0fc92a9a-5667-4159-fb65-df01c0999d29"
      },
      "source": [
        "print(num_cols_skewed_outliers_av)\n",
        "print(num_cols_norm_outliers_av)\n",
        "print(num_cols_norm_outliers_done_av)\n",
        "print(num_cols_skewed_done_av)\n",
        "print(num_cols_norm_av)\n",
        "print(num_cols_skewed_done_av)"
      ],
      "execution_count": 259,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Product_Category_1']\n",
            "[]\n",
            "[]\n",
            "['Product_Category_1_num_cols_skewed_outliers_cap']\n",
            "['User_ID', 'Occupation', 'Marital_Status', 'Product_Category_2', 'Product_Category_3', 'Product_Category_1_num_cols_skewed_log', 'Product_Category_1_num_cols_skewed_sqr', 'Product_Category_1_num_cols_skewed_outliers_cap']\n",
            "['Product_Category_1_num_cols_skewed_outliers_cap']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJRUcwI6qBxP"
      },
      "source": [
        "def outlier_fix(df, num_cols_skewed_outliers, num_cols_norm_outliers):\n",
        "  # normal distribution outliers capping the outliers trimming is done at the end of the df as 2 dfs with different shapes\n",
        "  # new_df = df[(df['cgpa'] < 8.80) & (df['cgpa'] > 5.11)]\n",
        "\n",
        "  \n",
        "  for col in num_cols_norm_outliers:\n",
        "    # capping the outliers normal\n",
        "    upper_limit_norm = df[col].mean() + 3*df[col].std()\n",
        "    lower_limit_norm = df[col].mean() - 3*df[col].std()\n",
        "    new_col = str(col)+'_num_cols_norm_outliers_cap'\n",
        "    df[new_col] = np.where(df[col]>upper_limit_norm, upper_limit_norm,np.where(df[col]<lower_limit_norm,lower_limit_norm,df[col]))\n",
        "    num_cols_norm_outliers_done.append(new_col)\n",
        "\n",
        "\n",
        "    # trimming\n",
        "    # df_trim = df[(df[col]>upper_limit_norm) & (df[col]< lower_limit_norm)]\n",
        "\n",
        "  for col in num_cols_skewed_outliers:\n",
        "    # capping the outliers skewed\n",
        "    q1 = df[col].quantile(0.25)\n",
        "    q3 = df[col].quantile(0.75)\n",
        "    iqr = q3-q1\n",
        "    upper_limit_skew = q1 + 1.5* iqr\n",
        "    lower_limit_skew = q1 - 1.5* iqr \n",
        "\n",
        "    new_col = str(col)+'_num_cols_skewed_outliers_cap'\n",
        "    df[str(col)+'_num_cols_skewed_outliers_cap'] = np.where(df[col] > upper_limit_skew,upper_limit_skew,np.where(df[col] < lower_limit_skew,lower_limit_skew,df[col]))\n",
        "    num_cols_skewed_outliers_done.append(new_col)\n",
        "    # trimming\n",
        "    # df_trim = df[(df[col]>upper_limit_skew) & (df[col]< lower_limit_skew)]\n",
        "\n",
        "  return df, num_cols_skewed_outliers_done, num_cols_norm_skewed_outliers_done\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yxj7B7PlOLHo"
      },
      "source": [
        "# Null columns identification and treatments\n",
        "\n",
        "* every column should undergo with null identification \n",
        "* previous input is the columns which are identified as categorical numerical and with some other variations of those columsn\n",
        "* filling the null values is done after skewed, outliers are capped or trimmed but it is good to keep the outliers in the list as some of the outliers maybe required for dataframes as it will symobolise all the items are taken considering the data preprocessing\n",
        "* whatever the feature filling the null values or removing the unessary null values is a must\n",
        "* for categoical features null value filling methods are differe from numerical features\n",
        "* so filling null values should do categorical and numerical basis\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NgFAY_PeiYH1"
      },
      "source": [
        "**up to this point all the identifications for corelated and outliers are fixed in each case where cat and numerical**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "epfR0cK0vshh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3ea6432-c2b7-4b49-f91e-bf67ac438594"
      },
      "source": [
        "av.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(550068, 12)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mwUv1QECI4sK",
        "outputId": "f46c4683-66ab-4365-ca0d-be265f1ae342"
      },
      "source": [
        "av['Product_Category_3'].isnull().sum()/av.shape[0]*100"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "69.67265865311198"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4qAFF4T7OaA1"
      },
      "source": [
        "# at the end all the features which are null have different list regarding that speciality of the feature\n",
        "# for egsample null columns which are normaly distributed are in 'num_cols_norm_null' where which are not null is in 'num_cols_norm'\n",
        "# each and every feat considered null are removed from the previoustly available list\n",
        "\n",
        "def null_identifier(df, num_cols_all,cat_cols_obj):\n",
        "  start_time = time.clock()\n",
        "  # null identify in the categorical columns with different types\n",
        "  for col in cat_cols_obj:\n",
        "    if df[col].isnull().sum()/df.shape[0] * 100 > 60:\n",
        "      cat_cols_obj_null_to_del.append(col)\n",
        "    elif df[col].isnull().sum()/df.shape[0] * 100 != 0:\n",
        "      cat_cols_obj_null.append(col)\n",
        "\n",
        "  # null identify in the numerical columns\n",
        "  for col in num_cols_all:\n",
        "    if df[col].isnull().sum()/df.shape[0] * 100 > 60:\n",
        "      num_cols_all_null_to_del.append(col)\n",
        "    elif df[col].isnull().sum()/df.shape[0] * 100 != 0:\n",
        "      num_cols_all_null.append(col)\n",
        "\n",
        "  # getting other columns filled \n",
        "  num_cols_cor_null = [i for i in num_cols_all_null if i in num_cols_cor]\n",
        "  num_cols_norm_null = [i for i in num_cols_all_null if i in num_cols_norm]\n",
        "  num_cols_skewed_null = [i for i in num_cols_all_null if i in num_cols_skewed]\n",
        "  num_cols_norm_outliers_null = [i for i in num_cols_all_null if i in num_cols_norm_outliers]\n",
        "  num_cols_skewed_outliers_null = [i for i in num_cols_all_null if i in num_cols_skewed_outliers]\n",
        "  # num_cols_skewed_outliers_null = [i for i in num_cols_all_null if i in num_cols_skewed_outliers]\n",
        "  # num_cols_skewed_null\n",
        "\n",
        "\n",
        "  \n",
        "\n",
        "  print(time.clock() - start_time, \"seconds took to finish null identifier\")\n",
        "\n",
        "  return cat_cols_obj_null, num_cols_all_null, num_cols_cor_null, num_cols_skewed_null, num_cols_norm_outliers_null, num_cols_skewed_outliers_null, cat_cols_obj_null_to_del, num_cols_all_null_to_del\n",
        "  # , num_cols_skewed_null, num_cols_norm_outliers_null, num_cols_skewed_outliers_null\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-_RarmmxMTCR",
        "outputId": "b3c50065-346e-4cb8-ffbc-ff78905b3892"
      },
      "source": [
        "# cat_cols_obj_null_av, num_cols_all_null_av, num_cols_cor_null_av, num_cols_skewed_null_av, num_cols_norm_outliers_null_av, num_cols_skewed_outliers_null_av = null_identifier(av, num_cols_all_av, cat_cols_obj_av)\n",
        "cat_cols_obj_null_av, num_cols_all_null_av, num_cols_cor_null_av, num_cols_skewed_null_av, num_cols_norm_outliers_null_av,num_cols_skewed_outliers_null_av = null_identifier(av, num_cols_all_av, cat_cols_obj_av)\n",
        "\n",
        "print('cat_cols_obj_null_av: ',cat_cols_obj_null_av)\n",
        "print('num_cols_all_null_av: ',num_cols_all_null_av)\n",
        "print('num_cols_cor_null_av: ',num_cols_cor_null_av)\n",
        "print('num_cols_skewed_null_av: ',num_cols_skewed_null_av)\n",
        "print('num_cols_norm_outliers_null_av: ',num_cols_norm_outliers_null_av)\n",
        "print('num_cols_skewed_outliers_null_av', num_cols_skewed_outliers_null_av)\n",
        "\n",
        "\n",
        "# num_cols_all = [i for i in df_copy.columns if i not in [target_col] and i not in id_cols and i not in cat_obj_cols]\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.12516999999999712 seconds took to finish null identifier\n",
            "cat_cols_obj_null_av:  []\n",
            "num_cols_all_null_av:  ['Product_Category_3']\n",
            "num_cols_cor_null_av:  []\n",
            "num_cols_skewed_null_av:  []\n",
            "num_cols_norm_outliers_null_av:  []\n",
            "num_cols_skewed_outliers_null_av []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3h5otCmhYMh"
      },
      "source": [
        "# comb['Age_null'] = np.where(comb['Age'].isnull(), 1, 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RR1K_gx_xPUi"
      },
      "source": [
        "# fixing the null features - all the features with null available needs to be fixed\n",
        "\n",
        "* at this stage of the project all the other data pre processing is done except null values and cat encoding \n",
        "* num_cols_cor_fixed, num_cols_skewed_fixed, "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OR4TxhR3X69t",
        "outputId": "662166cd-7174-4b4b-ba45-13784e6d47f9"
      },
      "source": [
        "av.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "User_ID                       0     \n",
              "Product_ID                    0     \n",
              "Gender                        0     \n",
              "Age                           0     \n",
              "Occupation                    0     \n",
              "City_Category                 0     \n",
              "Stay_In_Current_City_Years    0     \n",
              "Marital_Status                0     \n",
              "Product_Category_1            0     \n",
              "Product_Category_2            173638\n",
              "Product_Category_3            383247\n",
              "Purchase                      0     \n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2adkda8mQiZv",
        "outputId": "8f81e6e2-7dcf-4405-b475-922e93d600bf"
      },
      "source": [
        "av['Product_Category_3'].mean()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12.668243206790512"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pLu1h5aObYN2",
        "outputId": "c0880fae-a9ca-4234-c8fb-b3c62bc1846d"
      },
      "source": [
        "av['Product_Category_3'].max()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "18.0"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SwWZ9hgeniBF"
      },
      "source": [
        "def null_fix(df,cat_cols_obj_null_to_del, num_cols_all_null_to_del, cat_cols_obj_null,  num_cols_cor_null, num_cols_norm_null, num_cols_skewed_null, num_cols_norm_outliers_null, num_cols_skewed_outliers_null):\n",
        "  # fill null with extreme values numerical\n",
        "  # fill null with 'null' category \n",
        "  # make another column where null values are 0 and not null are 1\n",
        "  # mean null filling numerical\n",
        "  # median null filling numerical\n",
        "  # mode null filling numerical\n",
        "  # mode null filling categorical\n",
        "  # filling null with feature combining krish method\n",
        "  start_time = time.clock()\n",
        "\n",
        "  # delete the features in the del list\n",
        "  num_cat_cols_all_null_del = cat_cols_obj_null_to_del + num_cols_all_null_to_del\n",
        "  df_null_not_del = df.copy()\n",
        "  for col in num_cat_cols_all_null_del:\n",
        "    df.drop([col], axis=1, inplace=True) # delete all the null delete columns\n",
        "\n",
        "\n",
        "  # null filling in categorical features\n",
        "  for col in cat_cols_obj_null:\n",
        "\n",
        "    # create another feature wher null cols available\n",
        "    new_col = str(col)+'cat_cols_obj_null_binary'\n",
        "    df[new_col] = np.where(df[col].isnull(), 1,0)\n",
        "    cat_cols_obj_null_done.append(new_col)\n",
        "\n",
        "    # filling the null values with mode of the category\n",
        "    new_col = str(col)+'cat_cols_obj_null_mode'\n",
        "    df[new_col] = df[col].fillna(df[col].mode())\n",
        "    cat_cols_obj_null_done.append(new_col)\n",
        "\n",
        "    # filling the null values with another category of the category\n",
        "    new_col = str(col)+'cat_cols_obj_null_extreme'\n",
        "    df[new_col] = df[col].fillna('null')\n",
        "    cat_cols_obj_null_done.append(new_col)\n",
        "\n",
        "\n",
        "  # null filling in numerical features\n",
        "  for col in num_cols_cor_null:\n",
        "    # create another feature wher null cols available\n",
        "    new_col = str(col)+'num_cols_cor_null_binary'\n",
        "    df[new_col] = np.where(df[col].isnull(), 1,0)\n",
        "    num_cols_cor_null_done.append(new_col)\n",
        "\n",
        "    # filling the null values with mode of the category\n",
        "    new_col = str(col)+'num_cols_cor_null_mode'\n",
        "    df[new_col] = df[col].fillna(df[col].mode())\n",
        "    num_cols_cor_null_done.append(new_col)\n",
        "\n",
        "    # filling the null values with mean of the category\n",
        "    new_col = str(col)+'num_cols_cor_null_mode'\n",
        "    df[new_col] = df[col].fillna(df[col].mean())\n",
        "    num_cols_cor_null_done.append(new_col)\n",
        "\n",
        "    # filling the null values with mean of the category\n",
        "    new_col = str(col)+'num_cols_cor_null_median'\n",
        "    df[new_col] = df[col].fillna(df[col].median())\n",
        "    num_cols_cor_null_done.append(new_col)\n",
        "\n",
        "    # filling the null values with mean of the category\n",
        "    new_col = str(col)+'num_cols_cor_null_extreme'\n",
        "    max_val = df[col].max()\n",
        "    df[new_col] = df[col].fillna(max_val+1000)\n",
        "    num_cols_cor_null_done.append(new_col)\n",
        "    \n",
        "\n",
        "\n",
        "  for col in num_cols_norm_null:\n",
        "    # create another feature wher null cols available\n",
        "    new_col = str(col)+'num_cols_norm_null_binary'\n",
        "    df[new_col] = np.where(df[col].isnull(), 1,0)\n",
        "    num_cols_norm_null_done.append(new_col)\n",
        "\n",
        "    # filling the null values with mode of the category\n",
        "    new_col = str(col)+'num_cols_norm_null_mean'\n",
        "    df[new_col] = df[col].fillna(df[col].mode())\n",
        "    num_cols_norm_null_done.append(new_col)\n",
        "\n",
        "    # filling the null values with mode of the category\n",
        "    new_col = str(col)+'num_cols_norm_null_mode'\n",
        "    df[new_col] = df[col].fillna(df[col].mean())\n",
        "    num_cols_norm_null_done.append(new_col)\n",
        "\n",
        "    # filling the null values with mode of the category\n",
        "    new_col = str(col)+'num_cols_norm_null_median'\n",
        "    df[new_col] = df[col].fillna(df[col].median())\n",
        "    num_cols_norm_null_done.append(new_col)\n",
        "\n",
        "    # filling the null values with mean of the category\n",
        "    new_col = str(col)+'num_cols_cor_null_extreme'\n",
        "    max_val = df[col].max()\n",
        "    df[new_col] = df[col].fillna(max_val+1000)\n",
        "    num_cols_norm_null_done.append(new_col)\n",
        "\n",
        "  for col in num_cols_skewed_null:\n",
        "    # create another feature wher null cols available\n",
        "    new_col = str(col)+'num_cols_skewed_null_binary'\n",
        "    df[new_col] = np.where(df[col].isnull(), 1,0)\n",
        "    num_cols_skewed_null_done.append(new_col)\n",
        "\n",
        "    # filling the null values with mode of the category\n",
        "    new_col = str(col)+'num_cols_skewed_null_mode'\n",
        "    df[new_col] = df[col].fillna(df[col].mode())\n",
        "    num_cols_skewed_null_done.append(new_col)\n",
        " \n",
        "    # filling the null values with mode of the category\n",
        "    new_col = str(col)+'num_cols_skewed_null_mean'\n",
        "    df[new_col] = df[col].fillna(df[col].mean())\n",
        "    num_cols_skewed_null_done.append(new_col)\n",
        " \n",
        "    # filling the null values with mode of the category\n",
        "    new_col = str(col)+'num_cols_skewed_null_median'\n",
        "    df[new_col] = df[col].fillna(df[col].median())\n",
        "    num_cols_skewed_null_done.append(new_col)\n",
        "\n",
        "    # filling the null values with mean of the category\n",
        "    new_col = str(col)+'num_cols_cor_null_extreme'\n",
        "    max_val = df[col].max()\n",
        "    df[new_col] = df[col].fillna(max_val+1000)\n",
        "    num_cols_skewed_null_done.append(new_col)\n",
        "\n",
        "  for col in num_cols_skewed_outliers_null:\n",
        "    # create another feature wher null cols available\n",
        "    new_col = str(col)+'num_cols_skewed_outliers_null_binary'\n",
        "    df[new_col] = np.where(df[col].isnull(), 1,0)\n",
        "    num_cols_skewed_outliers_null_done.append(new_col)\n",
        "\n",
        "    # filling the null values with mode of the category\n",
        "    new_col = str(col)+'num_cols_skewed_outliers_null_mode'\n",
        "    df[new_col] = df[col].fillna(df[col].mode())\n",
        "    num_cols_skewed_outliers_null_done.append(new_col)\n",
        "\n",
        "    # filling the null values with mode of the category\n",
        "    new_col = str(col)+'num_cols_skewed_outliers_null_mean'\n",
        "    df[new_col] = df[col].fillna(df[col].mean())\n",
        "    num_cols_skewed_outliers_null_done.append(new_col)\n",
        "\n",
        "    # filling the null values with mode of the category\n",
        "    new_col = str(col)+'num_cols_skewed_outliers_null_median'\n",
        "    df[new_col] = df[col].fillna(df[col].median())\n",
        "    num_cols_skewed_outliers_null_done.append(new_col)\n",
        "\n",
        "    # filling the null values with mean of the category\n",
        "    new_col = str(col)+'num_cols_cor_null_extreme'\n",
        "    max_val = df[col].max()\n",
        "    df[new_col] = df[col].fillna(max_val+1000)\n",
        "    num_cols_skewed_outliers_null_done.append(new_col)\n",
        "\n",
        "\n",
        "  for col in num_cols_norm_outliers_null:\n",
        "    # create another feature wher null cols available\n",
        "    new_col = str(col)+'num_cols_norm_outliers_null_binary'\n",
        "    df[new_col] = np.where(df[col].isnull(), 1,0)\n",
        "    num_cols_norm_outliers_null_done.append(new_col)\n",
        "\n",
        "    # filling the null values with mode of the category\n",
        "    new_col = str(col)+'num_cols_norm_outliers_null_mode'\n",
        "    df[new_col] = df[col].fillna(df[col].mode())\n",
        "    num_cols_norm_outliers_null_done.append(new_col)\n",
        "\n",
        "    # filling the null values with mode of the category\n",
        "    new_col = str(col)+'num_cols_norm_outliers_null_mean'\n",
        "    df[new_col] = df[col].fillna(df[col].mean())\n",
        "    num_cols_norm_outliers_null_done.append(new_col)\n",
        "\n",
        "    # filling the null values with mode of the category\n",
        "    new_col = str(col)+'num_cols_norm_outliers_null_median'\n",
        "    df[new_col] = df[col].fillna(df[col].median())\n",
        "    num_cols_norm_outliers_null_done.append(new_col)\n",
        "\n",
        "    # filling the null values with mean of the category\n",
        "    new_col = str(col)+'num_cols_cor_null_extreme'\n",
        "    max_val = df[col].max()\n",
        "    df[new_col] = df[col].fillna(max_val+1000)\n",
        "    num_cols_norm_outliers_null_done.append(new_col)\n",
        "\n",
        "\n",
        "    # special null fix more customized methods to be continued in further final sets\n",
        "    # new_col = str(col)+'num_cols_cor_null_special'\n",
        "    # max_val = df[col].max()\n",
        "    # df[new_col] = df[col].fillna(max_val+1000)\n",
        "\n",
        "    # num_cols_norm_outliers_null_done.append(new_col)\n",
        "\n",
        "\n",
        "\n",
        "# at the end of the null filling all the null columns needs to be removed which means only null_done lists are proceed as well as not null ones\n",
        "  print(time.clock() - start_time, \"seconds took to finish null fix\")\n",
        "\n",
        "  return df, cat_cols_obj_null_done,  num_cols_cor_null_done, num_cols_norm_outliers_null_done, num_cols_skewed_outliers_null_done, num_cols_skewed_null_done, num_cols_norm_null_done"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZGqk117ORCl"
      },
      "source": [
        "# Categorical feature encoding various techniques\n",
        "\n",
        "* all the encoded features are standardized with the name \n",
        "* feature_list_name_tech/solution-name\n",
        "* One hot Encoding\n",
        "* Dummy Encoding\n",
        "*Effect Encoding\n",
        "*Binary Encoding\n",
        "*BaseN Encoding\n",
        "*Hash Encoding\n",
        "*Target Encoding\n",
        "\n",
        "kinds of categorical data-\n",
        "\n",
        "Ordinal Data: The categories have an inherent order- order is there where how many years person lived in a city\n",
        "\n",
        "Nominal Data: The categories do not have an inherent order - no order cities where people live\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EsAtsMogk9i3"
      },
      "source": [
        "import category_encoders as ce\n",
        "\n",
        "**create object of Ordinalencoding**\n",
        "\n",
        "encoder= ce.OrdinalEncoder(cols=['Degree'],return_df=True,                 mapping=[{'col':'Degree', 'mapping':{'None':0,'High school':1,'Diploma':2,'Bachelors':3,'Masters':4,'phd':5}}])\n",
        "\n",
        "fit and transform train data \n",
        "\n",
        "df_train_transformed = encoder.fit_transform(train_df)\n",
        "\n",
        "**Create object for one-hot encoding**\n",
        "\n",
        "encoder=ce.OneHotEncoder(cols='City',handle_unknown='return_nan',return_df=True,use_cat_names=True)\n",
        "\n",
        "Fit and transform Data\n",
        "\n",
        "data_encoded = encoder.fit_transform(data)\n",
        "\n",
        "\n",
        "encode the data\n",
        "\n",
        "data_encoded=pd.get_dummies(data=data,drop_first=True)\n",
        "\n",
        "\n",
        "\n",
        "Create object for hash encoder\n",
        "\n",
        "encoder=ce.HashingEncoder(cols='Month',n_components=6)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bYfgn5KtnSH1"
      },
      "source": [
        "\n",
        "\n",
        "*  in here the fixed cat cols encodes are not going to add to the dataframe they will be seperately kept in different lists and the previous categories are deleted\n",
        "* these categorical variables after encoded kept as different dataframes where at the end they can be concat to main df sets\n",
        "* data ordinal encoded features are added to the df\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ha9MyeQ1k9QC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "84r_hjjWHTav"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "def feat_encode(df, cat_cols_obj_null_done):\n",
        "\n",
        "  # at the end of all the encoding we have to delete all the columns which are categorical obj\n",
        "\n",
        "  for col in cat_cols_obj_null_done:\n",
        "\n",
        "    # categorical encoding one hot encoding only if the nuniques < 16\n",
        "\n",
        "    # label encoding for all as well as if > 16 in the above case\n",
        "    new_col = str(col)+'cat_cols_obj_null_done_label'\n",
        "    df[new_col] = LabelEncoder.fit_transorm(df[col])\n",
        "    cat_cols_obj_null_done_label_done.append(new_col)\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQn8kHk3HTav"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tnC7uk-3rsN8"
      },
      "source": [
        "# Standardize the features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SVayrQbsHTav"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EV24fw98HTav"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Mmeq6qvHTav"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tSS8iM8AHTaw"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xj3uT41kHTaw"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IhjOL2WSHTaw"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pdl1FSAKHTaw"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hdRovCLmHTaw"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nrdJkbQRHTaw"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sW21KpIGHTax"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZ_pTJsiHTax"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S3p9UJfAHTax"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zko9JJhpHTax"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ot887h-HTax"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vIQ_gFzHTax"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5aqw3M7YHTay"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "whi2oW9NHTay"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hOVB2kNGHTay"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UhdCzeblHTay"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "maNdgvq5HTay"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7yRfw2hAHTaz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}